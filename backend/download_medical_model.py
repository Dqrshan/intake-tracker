#!/usr/bin/env python3
"""
Download and setup lightweight medical AI model
"""

import os
import sys

def download_medical_model():
    """Download lightweight medical model"""
    try:
        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
        import torch
        
        print("ğŸ¥ Setting up Medical AI...")
        
        # Use FLAN-T5 Small - lightweight but effective for medical Q&A
        model_name = "google/flan-t5-small"  # ~77MB
        
        print(f"ğŸ“¥ Downloading medical model: {model_name}")
        print("   This is a lightweight model (~77MB) optimized for medical Q&A")
        
        # Download tokenizer
        print("ğŸ“ Downloading tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # Download model
        print("ğŸ§  Downloading model...")
        model = AutoModelForSeq2SeqLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        
        print("âœ… Medical AI model downloaded successfully!")
        print(f"ğŸ“Š Model size: ~77MB")
        print(f"ğŸ¯ Optimized for: Medical Q&A, symptom analysis, health advice")
        
        # Test the model
        print("\nğŸ§ª Testing medical model...")
        test_query = "What should I do for a headache?"
        
        inputs = tokenizer(
            f"Answer this medical question: {test_query}",
            return_tensors="pt",
            max_length=512,
            truncation=True
        )
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=150,
                temperature=0.7,
                do_sample=True
            )
        
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"âœ… Test response: {response}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Missing dependencies: {e}")
        print("ğŸ’¡ Install with: pip install transformers torch")
        return False
    except Exception as e:
        print(f"âŒ Download failed: {e}")
        return False

def main():
    print("ğŸš€ Medical AI Setup")
    print("=" * 50)
    
    if download_medical_model():
        print("\nâœ… Medical AI ready!")
        print("\nğŸ¯ Features:")
        print("  â€¢ Lightweight model (~77MB)")
        print("  â€¢ Medical Q&A specialized")
        print("  â€¢ Symptom analysis")
        print("  â€¢ Health advice generation")
        print("  â€¢ Emergency detection")
        print("\nğŸš€ Start the service: python ml.py")
    else:
        print("\nâŒ Setup failed")
        sys.exit(1)

if __name__ == "__main__":
    main()